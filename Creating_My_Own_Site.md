# Blog Post #1: Creating My Own Site

## Starting Out
Thoughtout the past year, I've noticed almost every single job application asks for your own website. I didn't really think much of it, but then I started to think about the different ways you could have your "own" blog or personal website. There's sort of a spectrum of options. On one end, you have websites like Medium that just require you to sign up and all you have to bring are the posts. And on the other end, you have running all of you own hardware out of your home and managing the machine yourself. I decided on somewhere in the middle by using AWS services and a domain registar. For the website itself, I settled on a small back end, wholly unnecessary but I just wanted to get more familiar with Go, and a React frontend. I'll probably introduce Tailwind at some point as well.

## Decisions, decisions
There wasn't a single or maybe even a handful of concrete reasons for the technologies, languages, or libraries I used. It ultimately came down to a combination of their popularity, my interest in them, and whether or not I have used them before. I decided I would make this website using React since I have never really used React before. These technologies are obviously overkill for what is essentially just plain text content, but I still would like to learn them and you have to start somewhere. I decided I wanted the ability to write posts in markdown directly to a Github repository and have it dynamically update on my website. This seemed like a great use case for a Go backend with an EC2 instance.

## The importance of doing stuff


## Exploration
I don't have a ton of experience with AWS or cloud providers in general. At this point in my career, most of my work has occurred at a large bank and all hosts were on premises and managed by the company across multiple data centers. I began by considering running one EC2 instance using a Go server and just serving static files and possibly endpoints as well. I may still do that. I didn't want to go through the hastle of getting my own SSL certificate from a 3rd party and putting it on my instance and AWS doesn't allow you to get certs for EC2 instances alone. You must have a load balancer in front of it. So, I decided to pivot to what I knew could work an S3 bucket with a Cloudfront distribution. This was stalled because AWS doesn't allow Cloudfront distributions on basic accounts it seems. Somehow, I discovered an AWS service called Amplify. I tried to go for Route53, but they don't support the .dev top-level domain. I'm very happy with how quickly I was able to get the EC2 and Go server up and running and I was very impressed with Amplify for web app hosting.

I didn't want to deal with certificates myself, so I was searching for the path of least resistance. At first I defaulted to what I know, I tried to create an S3 bucket and Cloudfront distribution but ran into issues with my AWS account. I also believe Cloudfront to be extreme overkill as I don't need the latency provided by distributing my files to the edge. I finally discovered Amplify and it had everything I wanted. Certificates are managed by the service. It has a workflow system that is able to hook into a Github repository and rebuild and commit changes to a particular branch. I was able to integrate the hosted website with my 3rd party domain registrar. There are some other nice features like being able to set up test pages that are linked to feature branches instead of the main branch.

The only thing left to do is create the main page and I want to create an automated system to upload posts by using this repository which will only have markdown files for each post. I plan on having my EC2 instance run a CRON job to pull the contents from this repository and copy the files into the Go file server directory. Then the React front end can dynamically retrieve new posts and add them to the website. I chose this polling mechanism over pushing as these aren't really time sensitive and running a commit hash comparison isn't all that expensive for a CRON job. As this repository grows in size it might be prudent to copy only new files or files that have changed between the new commit and the current local HEAD.

I chose markdown for blog post formats because it has a lot of support and the format is as close as you can get to universal for plain text rendering. I plan on using a Node library to parse and render the files into HTML on the client side and may try to write my own translator in the future. The other option is that I could have the Go server or some other mechanism translate the markdown posts into HTML and send the front end the preprocessed markdowns. I will look into that more in the future to see what tools are available it may just be easier to use some sort Unix tool before copying the files over. It is a micro EC2 instance so I figured the preprocessing isn't worth the extra stress, but this could change depending on what the Node library's performance looks like.

## Why I chose this method
If I wanted to just throw up a quick website I could have just used Squarespace or some other small website hosting service and that would have been valid considering how small the website was. I also could have just used Medium or some other website that relies on the users to be the content creators. I finally decided on the AWS approach to get some more experience with the platform even though I have used AWS RDS, EC2, S3, and Cloudfront before. I also wanted to go through the process of acquiring my own domain and setting that up.
